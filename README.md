# TextMining

Here lies code used to extract entity from raw text. 

See TokenPipeline for our two-stage token level entity recognition work. Preprocessed data and results are available in this folder. 

See Data&Preprocessing for the wtsv documents and codes used to transform them in form that can be understood by BERT-NER and FastText. Data spliting function is also included.

See TextClassification for a very simple example showing the performance of sentence-level classification.

## Other code that will appear here later:

Data preparation for usage of Solr search engine: some scripts used to generate json files containing information readable and necessary for Solr to index.
